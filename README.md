# Docker контейнеры. Docker под капотом 

## ДЗ Запуск VM с установленным Docker Engine при помощи Docker Machine. Написание Dockerfile и сборка образа с тестовым приложением. Сохранение образа на DockerHub.

 - [X] Создать docker host
 - [x] Создать свой образ
 - [x] Работа в Docker Hub
### Сделано
 - 104.155.4.61:9292
 - записано по условиям задания в файл docker-1.log
 - https://cloud.docker.com/u/hellcrazyrabbit/repository/docker/hellcrazyrabbit/otus-reddit

## Задание с *
 - пакер собирает образ, провижинер устанавливает на него докер
 - терраформ поднимает инфраструктуру
 - в ансибле прописаны плейбуки настройки приложения и установки докера 

# Docker образы. Микросервисы

## Разбиение приложения на несколько микросервисов. Выбор базового образа. Подключение volume к контейнеру.

 - [x] Собрать приложение используя образы сервисов
 - [x] Оптимизировать образы сервисов.
 - [x] Собрать приложение с использованием volume

### Комментарии
 - Для упрощенного развертывания использовать скрипт ../docker-monolith/docker-reddit.sh 

## Задания со *

 - [x] Запустить приложение изменив сетевые алиасы сервисов
`````
скрипт для передачи переменных env ../docker-monolith/docker-run.sh
`````

 - [x] Оптимизировать образы сервисов, используя alpine linux 
`````
Изменения можно посмотреть в различных версиях Dockerfile* в директориях сервисов
Для оптимизации использовался инструмент https://www.fromlatest.io/#/
`````

# Сетевое взаимодействие Docker контейнеров. Docker Compose. Тестирование образов 

- [x] Практика работы с сетями докер
- [x] Использование docker compose

## Docker-Compose
 - [x] Изменить docker-compose для работы с множеством сетей
 - [x] Параметизировать переменными

## Описание
 Домашняя работа выполнена по описанию из задания, протестированы разные сетевые мосты docker.
 
 Базовое имя проекта образуется дефолтной схемой <project>_<service>_<index> задать его можно самостоятельно флагом --project-name
или переменной COMPOSE_PROJECT_NAME. Это работает только для единичных контейнеров, при использовании stack деплоя выйдет ошибка, т.к.
каждый контейнер должен имень уникальное имя. Начиная с версии 1.23.0 схема имени стала длиньше <project>_<service>_<index>_<slug> 
#Gitlab CI. Построение процесса непрерывной интеграции

 - [x] Подготовить инсталяцию Gitlab CI
 - [x] Подготовить репозиторий с кодом приложения
 - [x] Описать для приложения этапы пайплайна
 - [x] Определить окружения

## Описание
 Задание выполнено согласно описания практической работы.

# Создание и запуск системы мониторинга Prometheus.
 - [x] Запуск и настройка Prometheus
 - [x] Мониторинг состояния микросервисов
 - [x] Сбор метрик хоста с использованием экспортера

## Описание
 - Репозиторий приведен к требуемому состоянию
 - Образы загружены на docker hub
https://cloud.docker.com/u/hellcrazyrabbit/repository/list
 - Самостоятельно проверены различные датчики prometheus

# Создание и запуск системы мониторинга Prometheus

 - [x] Мониторинг Docker контейнеров
 - [x] Визуализация метрик
 - [x] Сбор метрик различного характера (бизнес, статусных)
 - [x] Настройка и проверка алертинга

## Описание
 - cAdvisor используется для мониторинга контейнеров. Сервис добавлен в docker-compose-monitoring.yml 
Для просмотра перейти по url http://docker-host-ip:8080
 - Grafana используется для визуализации метрик. Так же добавлен в компоуз мониторинга.
Доступ по порту 3000
 - Дашборды для сбора различных типов метрик построены в Grafana
 - Alertmanager добавлен к уомпоузу и присоединен к слак каналу для уведомлений о сбоях.

Обновленные и новые образы добавлены на docker hub
https://cloud.docker.com/u/hellcrazyrabbit/repository/list

# Мониторинг приложения и инфраструктуры 
 - [x] Сбор неструктурированных логов
 - [x] Визуализация логов
 - [x] Сбор структурированных логов
 - [x] Распределенная трасировка

## Описание
 - Сбор логов осуществляется в сочетании инструментов EFK для этого создан отдельный компоуз файл
 - Визуализация логов происходит в Kibana
 - Парсинг неструктурированных логов проводим при помощи шаблонов grok в fluentd
 - Распределенная трасировка происходит при помощи Zipkin который уже внедрен в сервисы, включение происходит через .env

## Задание со *
  - [x] Распарсить полностью сообщение логов

`````
Добавлен шаблон grok для парса поля сообщения 
 grok_pattern service=%{WORD:service} \| event=%{WORD:event} \| path=%{URIPATH:path} \| request_id=%{GREEDYDATA:request_id} \| remote_addr=%{IPV4:remote_addr} \| method=%{GREEDYDATA:method} \| response_status=%{INT:response_status}
`````
 
 - [x] Понять причину жалоб на загрузку страницы пользователей в багованном приложении

`````
Не обнаружено описанных проблем, страница поста открывается за 13ms, создание поста занимает 63ms
Сервис на адресе http://104.197.242.113:9292
Zipkin http://104.197.242.113:9411
`````

# Kubernetes.Запуск кластера и приложения. Модель безопасности.
 - [x] Развернуть локальное окружение для работы с Kubernetes 
 - [x] Развернуть Kubernetes в GKE 
 - [x] Запустить reddit в Kubernetes

## Описание
 - Созданы все деплои, сервисы для k8s и наймспейс dev
 - В minikube version: v1.4.0 для активации аддона dashboard выполняем 
`````
minikube addons enable dashboard
`````
Для перехода в на страницу - minikube dashboard
 - Развернут кластер GKE для проверки работы приложения можно перейти по адресу 
http://35.202.115.7:30320/

# Kubernetes. Networks,  Storages
 - [x] Ingress Controller  
 - [x] Ingress. Secret. TLS  
 - [x] LoadBalancer Service 
 - [x] Network Policies 
 - [x] PersistentVolumes
 - [x] PersistentVolumeClaims

##Задание *
Описан манифест по добавлению TLS  объекта secret.yml

## Описание
 - Произведена установка и настройка всех объектов 
 - Дополнительно изучена возможность автодобавления TLS  по примеру https://mcs.mail.ru/help/settings-containers/letsencrypt
